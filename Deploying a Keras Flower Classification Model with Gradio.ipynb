{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdb58ee",
   "metadata": {},
   "source": [
    "# Deploying a Keras Flower Classification Model with Gradio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915ddf2",
   "metadata": {},
   "source": [
    "Deploying a Keras Flower Classification Model with Gradio.\n",
    "This article was published as a part of the Data Science Blogathon.\n",
    "\n",
    "Background on Flower Classification Model\n",
    "Deep learning models, especially CNN (Convolutional Neural Networks), are implemented to classify different objects with the help of labeled images. The models are trained with these images to great accuracy, tested, and then deployed for performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a88609",
   "metadata": {},
   "source": [
    "#Building a Flower Image Classifier using Keras.\n",
    "Import all the required libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a032cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39562d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and untar the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to see how many images are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the subdirectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dedf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see some images from the roses and daisy subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "daisy = list(data_dir.glob('daisy/*'))\n",
    "PIL.Image.open(str(daisy[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126e20a",
   "metadata": {},
   "source": [
    "#specify the batch size, which is the number of images used by the model during each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550057a",
   "metadata": {},
   "source": [
    "#Divide the images in an 80:20 ratio for classification. The training ratio is 0.8, whereas the validation ratio is 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec24a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17f66e",
   "metadata": {},
   "source": [
    "#calling the directory() function to read the validation images from the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62221c8",
   "metadata": {},
   "source": [
    "#Arrangig the dataset in alphabetical order to correspond with the directory names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a724d",
   "metadata": {},
   "source": [
    "#training dataset using the following code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(12):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building  the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a380c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888aedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c96ef",
   "metadata": {},
   "source": [
    "#View all the layers of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ab32a",
   "metadata": {},
   "source": [
    "#The convolution neural network will learn from training images to perform image classification. We are also setting the number of epochs to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify the model using predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721bf4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_image(img):\n",
    "  img_4d=img.reshape(-1,180,180,3)\n",
    "  prediction=model.predict(img_4d)[0]\n",
    "  return {class_names[i]: float(prediction[i]) for i in range(5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e55282",
   "metadata": {},
   "source": [
    "Deploying the Deep Learning Model Using Gradio\n",
    "Gradio is a machine learning library that transforms your trained machine learning model into an interactive application. Gradio provides simple user interfaces (UI) that enable users to interact with a trained machine learning model. It generates a web interface via which the user can test the trained model and view the prediction results. Gradioâ€™s user interface can be simply integrated straight into the Python notebook (either Jupyter notebook or Google Colab notebook) without the need to install any dependencies. Gradio interacts directly with popular machine learning libraries such as Sckit-learn, Tensorflow, Keras, PyTorch, and Hugging Face Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = gr.inputs.Image(shape=(180,180))\n",
    "label = gr.outputs.Label(num_top_classes=5)\n",
    "gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')\n",
    "print(\"Mr Kennedy Bwire ADM NO 21/02900\")\n",
    "print(\"Deploying a Keras Flower Classification Model with Gradio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69c3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
